import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="Analyseur CSV Pro", 
    page_icon="üìä", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# =============== CSS PERSONNALIS√â ================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f77b4;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .download-link {
        display: inline-block;
        background-color: #1f77b4;
        color: white;
        padding: 0.5rem 1rem;
        text-decoration: none;
        border-radius: 5px;
        margin: 0.2rem;
    }
    .download-link:hover {
        background-color: #155a8a;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# =============== FONCTIONS AM√âLIOR√âES =====================

def detect_outliers(series):
    """D√©tecte les outliers avec la m√©thode IQR de mani√®re robuste."""
    if len(series.dropna()) == 0:
        return 0
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    if IQR == 0:  # √âviter la division par z√©ro
        return 0
    return ((series < Q1 - 1.5*IQR) | (series > Q3 + 1.5*IQR)).sum()

def calculate_missing_percentage(df):
    """Calcule le % de valeurs manquantes par colonne avec plus de d√©tails."""
    missing = df.isnull().sum()
    percentage = (missing / len(df)) * 100
    # Convertir les types de donn√©es en string pour √©viter les probl√®mes de s√©rialisation
    dtypes_str = [str(dtype) for dtype in df.dtypes.values]
    missing_info = pd.DataFrame({
        'Colonne': missing.index,
        'Valeurs Manquantes': missing.values,
        'Pourcentage (%)': percentage.values.round(2),
        'Type de Donn√©es': dtypes_str
    }).sort_values('Pourcentage (%)', ascending=False)
    
    return missing_info

def generate_advanced_report(df):
    """G√©n√®re un rapport Markdown avanc√© et complet."""
    buffer = io.StringIO()
    
    buffer.write("# üìÑ Rapport d'Analyse D√©taill√©\n\n")
    buffer.write(f"**Date de G√©n√©ration:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    
    # Informations g√©n√©rales
    buffer.write("## üìä Informations G√©n√©rales\n")
    buffer.write(f"- **Nombre Total d'Observations:** {df.shape[0]:,}\n")
    buffer.write(f"- **Nombre de Variables:** {df.shape[1]}\n")
    buffer.write(f"- **Taille M√©moire Utilis√©e:** {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n\n")
    
    # Aper√ßu des donn√©es
    buffer.write("## üëÄ Aper√ßu du Dataset\n")
    buffer.write("### Premi√®res Lignes\n")
    buffer.write(df.head(10).to_markdown() + "\n\n")
    buffer.write("### Derni√®res Lignes\n")
    buffer.write(df.tail(5).to_markdown() + "\n\n")
    
    # Types de donn√©es
    buffer.write("## üîß Types de Donn√©es\n")
    type_summary = df.dtypes.reset_index()
    type_summary.columns = ['Colonne', 'Type']
    type_summary['Type'] = type_summary['Type'].astype(str)  # Convertir en string
    buffer.write(type_summary.to_markdown(index=False) + "\n\n")
    
    # Analyse des valeurs manquantes
    buffer.write("## ‚ö†Ô∏è Analyse des Valeurs Manquantes\n")
    missing_df = calculate_missing_percentage(df)
    buffer.write(missing_df.to_markdown(index=False) + "\n\n")
    
    # Statistiques descriptives
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        buffer.write("## üìà Statistiques Descriptives (Num√©riques)\n")
        buffer.write(df[numeric_cols].describe().round(2).to_markdown() + "\n\n")
    
    # Variables cat√©gorielles
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    if len(categorical_cols) > 0:
        buffer.write("## üìä Statistiques Descriptives (Cat√©gorielles)\n")
        for col in categorical_cols:
            buffer.write(f"### {col}\n")
            buffer.write(f"- **Valeurs Uniques:** {df[col].nunique()}\n")
            buffer.write(f"- **Valeur la plus Fr√©quente:** {df[col].mode().iloc[0] if len(df[col].mode()) > 0 else 'N/A'}\n")
            buffer.write(f"- **Fr√©quence de la Valeur Principale:** {df[col].value_counts().iloc[0] if len(df[col].value_counts()) > 0 else 0}\n\n")
    
    # D√©tection des outliers
    if len(numeric_cols) > 0:
        buffer.write("## üî¥ Analyse des Outliers (M√©thode IQR)\n")
        outliers_detected = False
        for col in numeric_cols:
            count = detect_outliers(df[col])
            if count > 0:
                buffer.write(f"- **{col}:** {count} outliers ({count/len(df)*100:.2f}%)\n")
                outliers_detected = True
        if not outliers_detected:
            buffer.write("Aucun outlier d√©tect√© dans les variables num√©riques.\n")
        buffer.write("\n")
    
    # Matrice de corr√©lation
    if len(numeric_cols) > 1:
        buffer.write("## üîó Matrice de Corr√©lation\n")
        corr_matrix = df[numeric_cols].corr()
        # Garder seulement la partie sup√©rieure de la matrice
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        corr_upper = corr_matrix.where(mask)
        buffer.write(corr_upper.round(3).to_markdown() + "\n\n")
    
    # Profil des variables
    buffer.write("## üéØ Profil des Variables\n")
    for col in df.columns:
        buffer.write(f"### {col}\n")
        buffer.write(f"- **Type:** {df[col].dtype}\n")
        buffer.write(f"- **Valeurs Uniques:** {df[col].nunique()}\n")
        if df[col].dtype in ['object', 'category']:
            top_values = df[col].value_counts().head(5)
            buffer.write("- **Top 5 Valeurs:**\n")
            for val, count in top_values.items():
                buffer.write(f"  - {val}: {count} ({count/len(df)*100:.1f}%)\n")
        else:
            buffer.write(f"- **Moyenne:** {df[col].mean():.2f}\n")
            buffer.write(f"- **M√©diane:** {df[col].median():.2f}\n")
            buffer.write(f"- **√âcart-type:** {df[col].std():.2f}\n")
        buffer.write("\n")
    
    return buffer.getvalue()

def create_download_link(content, filename, text):
    """Cr√©e un lien de t√©l√©chargement pour le contenu textuel."""
    b64 = base64.b64encode(content.encode()).decode()
    href = f'<a href="data:file/txt;base64,{b64}" download="{filename}" class="download-link">{text}</a>'
    return href

def create_data_download_link(df, filename, text, format_type='csv'):
    """Cr√©e un lien de t√©l√©chargement pour les donn√©es."""
    if format_type == 'csv':
        data = df.to_csv(index=False).encode('utf-8')
        mime_type = "text/csv"
    elif format_type == 'json':
        data = df.to_json(orient='records', indent=2).encode('utf-8')
        mime_type = "application/json"
    elif format_type == 'excel':
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Data')
        data = buffer.getvalue()
        mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    
    b64 = base64.b64encode(data).decode()
    href = f'<a href="data:{mime_type};base64,{b64}" download="{filename}" class="download-link">{text}</a>'
    return href

def plot_advanced_visualizations(df):
    """Cr√©e des visualisations avanc√©es pour le dataset."""
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    
    figures = []
    
    # Distribution des variables num√©riques
    if len(numeric_cols) > 0:
        n_cols = min(3, len(numeric_cols))
        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols
        
        fig1, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
        if n_rows == 1 and n_cols == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes
        else:
            axes = axes.flatten()
        
        for i, col in enumerate(numeric_cols):
            if i < len(axes):
                axes[i].hist(df[col].dropna(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')
                axes[i].set_title(f'Distribution de {col}')
                axes[i].set_xlabel(col)
                axes[i].set_ylabel('Fr√©quence')
        
        # Masquer les axes vides
        for i in range(len(numeric_cols), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        figures.append(("Distribution des Variables Num√©riques", fig1))
    
    # Boxplots pour outliers
    if len(numeric_cols) > 0:
        n_cols = min(3, len(numeric_cols))
        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols
        
        fig2, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
        if n_rows == 1 and n_cols == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = axes
        else:
            axes = axes.flatten()
        
        for i, col in enumerate(numeric_cols):
            if i < len(axes):
                axes[i].boxplot(df[col].dropna())
                axes[i].set_title(f'Boxplot de {col}')
                axes[i].set_ylabel(col)
        
        for i in range(len(numeric_cols), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        figures.append(("Analyse des Outliers", fig2))
    
    # Top cat√©gories pour variables cat√©gorielles
    if len(categorical_cols) > 0:
        for col in categorical_cols[:3]:  # Limiter aux 3 premi√®res
            fig3, ax = plt.subplots(figsize=(10, 6))
            top_categories = df[col].value_counts().head(10)
            top_categories.plot(kind='bar', ax=ax, color='lightcoral')
            ax.set_title(f'Top 10 Cat√©gories - {col}')
            ax.set_xlabel(col)
            ax.set_ylabel('Fr√©quence')
            plt.xticks(rotation=45)
            plt.tight_layout()
            figures.append((f"Top Cat√©gories - {col}", fig3))
    
    return figures

# =============== INTERFACE PRINCIPALE ================

st.markdown('<h1 class="main-header">üìä Analyseur Automatique de Fichiers CSV</h1>', unsafe_allow_html=True)
st.markdown("""
<div style='text-align: center; margin-bottom: 2rem;'>
    <p style='font-size: 1.2rem; color: #666;'>
        Chargez un fichier CSV pour obtenir une analyse compl√®te et professionnelle de vos donn√©es
    </p>
</div>
""", unsafe_allow_html=True)

# Sidebar pour les param√®tres
with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres")
    st.markdown("---")
    
    # Options d'analyse
    st.subheader("Options d'Analyse")
    auto_analyze = st.checkbox("Analyse automatique", value=True)
    show_correlations = st.checkbox("Afficher les corr√©lations", value=True)
    detect_outliers_option = st.checkbox("D√©tection des outliers", value=True)
    
    st.markdown("---")
    st.subheader("√Ä propos")
    st.info("""
    Cet outil vous permet d'analyser vos donn√©es CSV de mani√®re professionnelle :
    - üìä Statistiques descriptives
    - üîç D√©tection des valeurs manquantes
    - üìà Visualisations avanc√©es
    - üßπ Nettoyage des donn√©es
    - üìÑ Rapports d√©taill√©s
    """)

uploaded_file = st.file_uploader("**Choisissez un fichier CSV**", type=["csv"], 
                                help="S√©lectionnez un fichier CSV √† analyser")

if uploaded_file is not None:
    try:
        # Lecture du fichier avec gestion d'erreurs
        df = pd.read_csv(uploaded_file)
        st.success(f"‚úÖ Fichier charg√© avec succ√®s : {uploaded_file.name}")
        
        # M√©triques principales dans des cartes
        st.markdown("## üìà M√©triques Principales")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
            <div class="metric-card">
                <h3>üìè Lignes</h3>
                <h2>{df.shape[0]:,}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-card">
                <h3>üìã Colonnes</h3>
                <h2>{df.shape[1]}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            missing_total = df.isnull().sum().sum()
            st.markdown(f"""
            <div class="metric-card">
                <h3>‚ö†Ô∏è Donn√©es Manquantes</h3>
                <h2>{missing_total:,}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            memory_mb = df.memory_usage(deep=True).sum() / 1024**2
            st.markdown(f"""
            <div class="metric-card">
                <h3>üíæ M√©moire</h3>
                <h2>{memory_mb:.1f} MB</h2>
            </div>
            """, unsafe_allow_html=True)
        
        # Organisation en onglets
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            "üîç Aper√ßu", "üìä Analyse", "üìà Visualisations", 
            "üßπ Nettoyage", "üì• Export", "üìÑ Rapport"
        ])
        
        # ========== TAB 1 : APER√áU ==========
        with tab1:
            st.subheader("üëÄ Exploration des Donn√©es")
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.write("**Aper√ßu des donn√©es :**")
                st.dataframe(df.head(20), width='stretch')
            
            with col2:
                st.write("**Types de donn√©es :**")
                dtype_df = df.dtypes.reset_index()
                dtype_df.columns = ['Colonne', 'Type']
                dtype_df['Type'] = dtype_df['Type'].astype(str)  # Convertir en string
                st.dataframe(dtype_df, width='stretch')
                
                st.write("**R√©sum√© des donn√©es :**")
                st.json({
                    "Dimensions": f"{df.shape[0]} lignes √ó {df.shape[1]} colonnes",
                    "Colonnes Num√©riques": len(df.select_dtypes(include=[np.number]).columns),
                    "Colonnes Cat√©gorielles": len(df.select_dtypes(include=['object']).columns),
                    "Valeurs Dupliqu√©es": df.duplicated().sum()
                })
        
        # ========== TAB 2 : ANALYSE ==========
        with tab2:
            st.subheader("üìä Analyse Statistique")
            
            # Analyse des valeurs manquantes
            st.write("### ‚ö†Ô∏è Analyse des Valeurs Manquantes")
            missing_df = calculate_missing_percentage(df)
            st.dataframe(missing_df, width='stretch')
            
            # Statistiques descriptives
            st.write("### üìà Statistiques Descriptives")
            
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                st.dataframe(df[numeric_cols].describe(), width='stretch')
            else:
                st.info("Aucune colonne num√©rique trouv√©e pour les statistiques descriptives.")
            
            # Analyse des corr√©lations
            if show_correlations and len(numeric_cols) > 1:
                st.write("### üîó Matrice de Corr√©lation")
                fig, ax = plt.subplots(figsize=(10, 8))
                sns.heatmap(df[numeric_cols].corr(), annot=True, fmt=".2f", cmap="coolwarm", 
                           center=0, cbar_kws={"label": "Coefficient de Corr√©lation"}, ax=ax)
                st.pyplot(fig)
            
            # D√©tection des outliers
            if detect_outliers_option and len(numeric_cols) > 0:
                st.write("### üî¥ D√©tection des Outliers")
                outliers_data = []
                for col in numeric_cols:
                    count = detect_outliers(df[col])
                    if count > 0:
                        outliers_data.append({
                            'Colonne': col,
                            'Outliers': count,
                            'Pourcentage': f"{(count/len(df))*100:.2f}%"
                        })
                
                if outliers_data:
                    outliers_df = pd.DataFrame(outliers_data)
                    st.dataframe(outliers_df, width='stretch')
                else:
                    st.success("Aucun outlier d√©tect√© dans les donn√©es num√©riques.")
        
        # ========== TAB 3 : VISUALISATIONS ==========
        with tab3:
            st.subheader("üìà Visualisations des Donn√©es")
            
            if auto_analyze:
                st.write("### üé® Visualisations Automatiques")
                figures = plot_advanced_visualizations(df)
                
                for title, fig in figures:
                    st.write(f"**{title}**")
                    st.pyplot(fig)
                    st.markdown("---")
            
            # Visualisations interactives
            st.write("### üéõÔ∏è Visualisations Personnalis√©es")
            
            col1, col2 = st.columns(2)
            
            with col1:
                x_axis = st.selectbox("Axe X:", df.columns, key="x_axis")
            
            with col2:
                y_axis = st.selectbox("Axe Y:", ['Aucun'] + list(df.columns), key="y_axis")
            
            if y_axis != 'Aucun' and df[x_axis].dtype in [np.number] and df[y_axis].dtype in [np.number]:
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.scatter(df[x_axis], df[y_axis], alpha=0.6)
                ax.set_xlabel(x_axis)
                ax.set_ylabel(y_axis)
                ax.set_title(f'Relation entre {x_axis} et {y_axis}')
                st.pyplot(fig)
        
        # ========== TAB 4 : NETTOYAGE ==========
        with tab4:
            st.subheader("üßπ Outils de Nettoyage des Donn√©es")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("### Suppression des Donn√©es")
                
                # Suppression des lignes avec valeurs manquantes
                if st.button("üóëÔ∏è Supprimer Lignes avec Valeurs Manquantes", use_container_width=True):
                    df_clean = df.dropna()
                    rows_deleted = len(df) - len(df_clean)
                    st.success(f"‚úÖ {rows_deleted} lignes supprim√©es")
                    st.dataframe(df_clean.head(), width='stretch')
                    
                    # Lien de t√©l√©chargement
                    st.markdown(create_data_download_link(
                        df_clean, "data_cleaned_dropna.csv", "üì• T√©l√©charger les Donn√©es Nettoy√©es"
                    ), unsafe_allow_html=True)
                
                # Suppression des colonnes avec trop de valeurs manquantes
                st.write("### S√©lection des Colonnes")
                columns_to_keep = st.multiselect(
                    "Choisissez les colonnes √† conserver:",
                    df.columns.tolist(),
                    default=df.columns.tolist()
                )
                
                if columns_to_keep:
                    df_filtered = df[columns_to_keep]
                    st.dataframe(df_filtered.head(), width='stretch')
                    
                    st.markdown(create_data_download_link(
                        df_filtered, "data_filtered_columns.csv", "üì• T√©l√©charger avec Colonnes S√©lectionn√©es"
                    ), unsafe_allow_html=True)
            
            with col2:
                st.write("### Transformation des Donn√©es")
                
                # Imputation des valeurs manquantes
                if st.button("üîß Imputer Valeurs Manquantes", use_container_width=True):
                    df_imputed = df.copy()
                    
                    for col in df_imputed.columns:
                        if df_imputed[col].dtype in [np.float64, np.int64]:
                            # Pour les num√©riques : moyenne ou m√©diane
                            if df_imputed[col].skew() > 1:  # Distribution asym√©trique
                                df_imputed[col] = df_imputed[col].fillna(df_imputed[col].median())
                            else:
                                df_imputed[col] = df_imputed[col].fillna(df_imputed[col].mean())
                        else:
                            # Pour les cat√©gorielles : mode
                            if len(df_imputed[col].mode()) > 0:
                                df_imputed[col] = df_imputed[col].fillna(df_imputed[col].mode()[0])
                            else:
                                df_imputed[col] = df_imputed[col].fillna("Inconnu")
                    
                    st.success("‚úÖ Valeurs manquantes imput√©es")
                    st.dataframe(df_imputed.head(), width='stretch')
                    
                    st.markdown(create_data_download_link(
                        df_imputed, "data_imputed.csv", "üì• T√©l√©charger les Donn√©es Imput√©es"
                    ), unsafe_allow_html=True)
                
                # Normalisation des donn√©es num√©riques
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 0:
                    if st.button("üìä Normaliser Donn√©es Num√©riques", use_container_width=True):
                        df_normalized = df.copy()
                        for col in numeric_cols:
                            # √âviter la division par z√©ro
                            col_min = df[col].min()
                            col_max = df[col].max()
                            if col_max != col_min:
                                df_normalized[col] = (df[col] - col_min) / (col_max - col_min)
                            else:
                                df_normalized[col] = 0.5  # Valeur constante
                        
                        st.success("‚úÖ Donn√©es num√©riques normalis√©es (0-1)")
                        st.dataframe(df_normalized.head(), width='stretch')
                        
                        st.markdown(create_data_download_link(
                            df_normalized, "data_normalized.csv", "üì• T√©l√©charger les Donn√©es Normalis√©es"
                        ), unsafe_allow_html=True)
        
        # ========== TAB 5 : EXPORT ==========
        with tab5:
            st.subheader("üì• Export des Donn√©es")
            
            st.write("### T√©l√©charger dans Diff√©rents Formats")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown(create_data_download_link(
                    df, "dataset_analyse.csv", "üì• T√©l√©charger en CSV", 'csv'
                ), unsafe_allow_html=True)
            
            with col2:
                st.markdown(create_data_download_link(
                    df, "dataset_analyse.json", "üì• T√©l√©charger en JSON", 'json'
                ), unsafe_allow_html=True)
            
            with col3:
                st.markdown(create_data_download_link(
                    df, "dataset_analyse.xlsx", "üì• T√©l√©charger en Excel", 'excel'
                ), unsafe_allow_html=True)
            
            # Export des donn√©es transform√©es
            st.write("### Donn√©es Transform√©es")
            st.info("Utilisez l'onglet 'Nettoyage' pour appliquer des transformations avant l'export.")
        
        # ========== TAB 6 : RAPPORT ==========
        with tab6:
            st.subheader("üìÑ Rapport d'Analyse Complet")
            
            if st.button("üîÑ G√©n√©rer le Rapport", type="primary"):
                with st.spinner("G√©n√©ration du rapport en cours..."):
                    report_content = generate_advanced_report(df)
                
                st.success("‚úÖ Rapport g√©n√©r√© avec succ√®s!")
                
                # Aper√ßu du rapport
                st.write("### Aper√ßu du Rapport")
                st.markdown(report_content[:1000] + "..." if len(report_content) > 1000 else report_content)
                
                # T√©l√©chargement du rapport
                st.write("### T√©l√©chargement")
                st.markdown(create_download_link(
                    report_content, 
                    f"rapport_analyse_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                    "üì• T√©l√©charger le Rapport Complet (Markdown)"
                ), unsafe_allow_html=True)
                
                # R√©sum√© ex√©cutif
                st.write("### üìã R√©sum√© Ex√©cutif")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    total_cells = df.shape[0] * df.shape[1]
                    missing_cells = df.isnull().sum().sum()
                    data_quality = ((total_cells - missing_cells) / total_cells * 100) if total_cells > 0 else 100
                    st.metric("Qualit√© Globale des Donn√©es", f"{data_quality:.1f}%")
                    st.metric("Variables Num√©riques", len(df.select_dtypes(include=[np.number]).columns))
                
                with col2:
                    completeness_rate = (1 - missing_cells / total_cells) * 100 if total_cells > 0 else 100
                    st.metric("Taux de Compl√©tude", f"{completeness_rate:.1f}%")
                    st.metric("Variables Cat√©gorielles", len(df.select_dtypes(include=['object']).columns))
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la lecture du fichier: {str(e)}")
        st.info("""
        **Conseils de d√©pannage :**
        - V√©rifiez que le fichier est un CSV valide
        - Assurez-vous que l'encodage est correct (UTF-8 recommand√©)
        - V√©rifiez les s√©parateurs utilis√©s
        - Contr√¥lez la coh√©rence des donn√©es
        """)

else:
    # Page d'accueil quand aucun fichier n'est charg√©
    st.markdown("""
    <div style='text-align: center; padding: 5rem;'>
        <h2>üöÄ Bienvenue dans l'Analyseur CSV Pro</h2>
        <p style='font-size: 1.1rem; color: #666; margin-bottom: 3rem;'>
            Commencez par charger un fichier CSV pour d√©couvrir toutes les fonctionnalit√©s d'analyse
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div style='text-align: center;'>
            <h3>üìä Analyse Compl√®te</h3>
            <p>Statistiques descriptives, corr√©lations, d√©tection d'outliers</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div style='text-align: center;'>
            <h3>üßπ Nettoyage Intelligent</h3>
            <p>Gestion des valeurs manquantes, normalisation, filtrage</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div style='text-align: center;'>
            <h3>üìà Visualisations Avanc√©es</h3>
            <p>Graphiques interactifs, analyses multidimensionnelles</p>
        </div>
        """, unsafe_allow_html=True)

# Pied de page
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9rem;'>
    <p>Analyseur CSV Pro ‚Ä¢ D√©velopp√© avec Streamlit</p>
</div>
""", unsafe_allow_html=True)